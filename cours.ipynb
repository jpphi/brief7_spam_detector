{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# **Éléments de cours sur le Natural Language Processing**  \n",
    "\n",
    "https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32\n",
    "\n",
    "Natural Language Processing is the technology used to aid computers to understand the human’s natural language.\n",
    "\n",
    "L'objectif ultime de la NLP/PNL est de lire, déchiffrer, comprendre et donner un sens aux langues humaines d'une manière qui soit valable.\n",
    "\n",
    "Pourquoi es-ce difficile à réaliser?\n",
    "C'est la nature même du language humain qui rend le PLN difficile\n",
    "Les tournures de phrase, l'intention (humour, sarcasmes,...), les ambigüetés des tournures de phrase\n",
    "\n",
    "L'orthographe et les règles de grammaire sont des règles de bas niveau (donc facile à priori) mais les fautes sont nombreuses dans le langages courants.\n",
    "\n",
    "Il faut comprendre les mots, mais aussi la façon dont ils sont liès\n",
    "\n",
    "Comment fonctionne le traitement du langage naturel ?\n",
    "\n",
    "La PNL consiste à appliquer des algorithmes pour identifier et extraire les règles du langage naturel de telle sorte que les données linguistiques non structurées soient converties sous une forme que les ordinateurs peuvent comprendre.\n",
    "\n",
    "Lorsque le texte a été fourni, l'ordinateur utilise des algorithmes pour extraire le sens associé à chaque phrase et en recueillir les données essentielles.\n",
    "\n",
    "Parfois, l'ordinateur peut ne pas bien comprendre le sens d'une phrase.\n",
    "\n",
    "Les techniques utilisé en NLP?\n",
    "\n",
    "l'analyse syntaxique et l'analyse sémantique sont les principales techniques utilisées.\n",
    "\n",
    "\n",
    "1. Syntaxe\n",
    "\n",
    "La syntaxe désigne l'agencement des mots dans une phrase de manière à ce qu'ils aient un sens grammatical.\n",
    "\n",
    "En PNL, l'analyse syntaxique est utilisée pour évaluer comment la langue naturelle s'aligne sur les règles grammaticales.\n",
    "\n",
    "Les algorithmes informatiques sont utilisés pour appliquer les règles grammaticales à un groupe de mots et en tirer un sens.\n",
    "\n",
    "Voici quelques techniques syntaxiques qui peuvent être utilisées :\n",
    "\n",
    "    La lemmatisation : Elle consiste à réduire les différentes formes infléchies d'un mot en une seule forme pour en faciliter l'analyse.\n",
    "    \n",
    "    Segmentation morphologique : Elle consiste à diviser les mots en unités individuelles appelées morphèmes.\n",
    "    \n",
    "    Segmentation des mots : Elle consiste à diviser un grand morceau de texte continu en unités distinctes.\n",
    "    \n",
    "    Balisage de la partie du discours : Il s'agit d'identifier la partie du discours pour chaque mot.\n",
    "    \n",
    "    Parsing : Il s'agit d'effectuer une analyse grammaticale de la phrase fournie.\n",
    "    \n",
    "    Rupture de phrase : Il s'agit de placer les limites d'une phrase sur une grande partie du texte.\n",
    "    \n",
    "    Ebouriffage : Il s'agit de couper les mots infléchis à leur racine.\n",
    "\n",
    "2. Sémantique\n",
    "\n",
    "La sémantique se réfère au sens véhiculé par un texte. L'analyse sémantique est l'un des aspects difficiles du traitement du langage naturel qui n'a pas encore été entièrement résolu.\n",
    "\n",
    "Elle consiste à appliquer des algorithmes informatiques pour comprendre le sens et l'interprétation des mots et la façon dont les phrases sont structurées.\n",
    "\n",
    "Voici quelques techniques d'analyse sémantique :\n",
    "\n",
    "    Reconnaissance d'entités nommées (NER) : Elle consiste à déterminer les parties d'un texte qui peuvent être identifiées et classées dans des groupes prédéfinis. Les noms de personnes et les noms de lieux sont des exemples de tels groupes.\n",
    "    \n",
    "    Désambiguïsation du sens des mots : Il s'agit de donner un sens à un mot en fonction du contexte.\n",
    "    \n",
    "    Génération du langage naturel : Il s'agit d'utiliser des bases de données pour dériver des intentions sémantiques et les convertir en langage humain.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Le traitement du langage naturel joue un rôle essentiel dans le soutien des interactions entre la machine et l'homme.\n",
    "\n",
    "Au fur et à mesure que la recherche se développe dans ce domaine, nous nous attendons à voir d'autres percées qui rendront les machines plus intelligentes pour reconnaître et comprendre le langage humain.\n",
    "\n",
    "\n",
    "LIENS 2\n",
    "https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1\n",
    "....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Votre guide sur le traitement du langage naturel (NLP)\n",
    "Comment les machines traitent et comprennent le langage humain\n",
    "Diego Lopez Yse\n",
    "Diego Lopez Yse\n",
    "15 janv. 2019-13 min lire\n",
    "Image pour la poste\n",
    "Image pour la poste\n",
    "\n",
    "Tout ce que nous exprimons (verbalement ou par écrit) est porteur d'une quantité énorme d'informations. Le sujet que nous choisissons, notre ton, notre sélection de mots, tout ajoute un type d'information qui peut être interprété et dont on peut tirer une valeur. En théorie, nous pouvons comprendre et même prévoir le comportement humain en utilisant ces informations.\n",
    "\n",
    "Mais il y a un problème : une personne peut générer des centaines ou des milliers de mots dans une déclaration, chaque phrase avec sa complexité correspondante. Si vous voulez mettre à l'échelle et analyser plusieurs centaines, milliers ou millions de personnes ou de déclarations dans une zone géographique donnée, alors la situation est ingérable.\n",
    "\n",
    "Les données générées à partir de conversations, de déclarations ou même de tweets sont des exemples de données non structurées. Les données non structurées ne s'intègrent pas parfaitement dans la structure traditionnelle de lignes et de colonnes des bases de données relationnelles, et représentent la grande majorité des données disponibles dans le monde réel. Elles sont désordonnées et difficiles à manipuler. Néanmoins, grâce aux progrès réalisés dans des disciplines comme l'apprentissage machine, une grande révolution est en cours à ce sujet. Aujourd'hui, il ne s'agit plus d'essayer d'interpréter un texte ou un discours à partir de ses mots clés (la méthode mécanique à l'ancienne), mais de comprendre le sens de ces mots (la méthode cognitive). Il est ainsi possible de détecter des figures de style comme l'ironie, ou même d'effectuer une analyse des sentiments.\n",
    "\n",
    "    Le traitement du langage naturel ou PNL est un domaine de l'intelligence artificielle qui donne aux machines la capacité de lire, de comprendre et de tirer un sens des langues humaines.\n",
    "\n",
    "C'est une discipline qui se concentre sur l'interaction entre la science des données et le langage humain, et qui s'étend à de nombreuses industries. Aujourd'hui, la PNL est en plein essor grâce aux améliorations considérables de l'accès aux données et à l'augmentation de la puissance de calcul, qui permettent aux praticiens d'obtenir des résultats significatifs dans des domaines tels que les soins de santé, les médias, la finance et les ressources humaines, entre autres.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Cas d'utilisation de la PNL\n",
    "\n",
    "En termes simples, la PNL représente le traitement automatique du langage humain naturel comme la parole ou le texte, et bien que le concept lui-même soit fascinant, la valeur réelle derrière cette technologie provient des cas d'utilisation.\n",
    "\n",
    "La PNL peut vous aider dans de nombreuses tâches et les champs d'application semblent s'élargir chaque jour. Citons quelques exemples :\n",
    "\n",
    "    La PNL permet la reconnaissance et la prédiction de maladies sur la base des dossiers médicaux électroniques et de la parole du patient. Cette capacité est explorée dans des conditions de santé qui vont des maladies cardiovasculaires à la dépression et même à la schizophrénie. Par exemple, Amazon Comprehend Medical est un service qui utilise la PNL pour extraire les états pathologiques, les médicaments et les résultats des traitements à partir des notes des patients, des rapports d'essais cliniques et d'autres dossiers de santé électroniques.\n",
    "    Les organisations peuvent déterminer ce que les clients disent d'un service ou d'un produit en identifiant et en extrayant des informations dans des sources comme les médias sociaux. Cette analyse des sentiments peut fournir de nombreuses informations sur les choix des clients et les facteurs de décision.\n",
    "    Un inventeur d'IBM a mis au point un assistant cognitif qui fonctionne comme un moteur de recherche personnalisé en apprenant tout sur vous et en vous rappelant un nom, une chanson ou tout ce dont vous ne vous souvenez pas au moment où vous en avez besoin.\n",
    "    Des entreprises comme Yahoo et Google filtrent et classent vos e-mails avec la PNL en analysant le texte des e-mails qui transitent par leurs serveurs et en arrêtant le spam avant même qu'il n'entre dans votre boîte de réception.\n",
    "    Pour aider à identifier les fausses nouvelles, le groupe de PNL du MIT a développé un nouveau système permettant de déterminer si une source est exacte ou politiquement biaisée, en détectant si une source d'information est fiable ou non.\n",
    "    Alexa d'Amazon et Siri d'Apple sont des exemples d'interfaces vocales intelligentes qui utilisent la PNL pour répondre à des messages vocaux et faire tout comme trouver un magasin en particulier, nous indiquer les prévisions météorologiques, nous suggérer le meilleur itinéraire pour se rendre au bureau ou allumer les lumières à la maison.\n",
    "    Avoir un aperçu de ce qui se passe et de ce dont les gens parlent peut être très précieux pour les opérateurs financiers. La PNL est utilisée pour suivre les nouvelles, les rapports, les commentaires sur d'éventuelles fusions entre entreprises, tout peut ensuite être intégré dans un algorithme de trading pour générer des profits massifs. N'oubliez pas : achetez la rumeur, vendez les nouvelles.\n",
    "    La PNL est également utilisée dans les phases de recherche et de sélection du recrutement de talents, pour identifier les compétences des personnes susceptibles d'être embauchées et aussi pour repérer les prospects avant qu'ils ne deviennent actifs sur le marché du travail.\n",
    "    Utilisant la technologie de la PNL d'IBM Watson, LegalMation a développé une plateforme pour automatiser les tâches de routine en matière de litiges et aider les équipes juridiques à gagner du temps, à réduire les coûts et à changer d'orientation stratégique.\n",
    "\n",
    "La PNL est particulièrement en plein essor dans le secteur des soins de santé. Cette technologie améliore la prestation des soins, le diagnostic des maladies et réduit les coûts, tandis que les organismes de soins de santé adoptent de plus en plus les dossiers médicaux électroniques. Le fait que la documentation clinique puisse être améliorée signifie que les patients peuvent être mieux compris et bénéficier de meilleurs soins de santé. L'objectif devrait être d'optimiser leur expérience, et plusieurs organisations y travaillent déjà.\n",
    "Image pour la poste\n",
    "Image pour la poste\n",
    "Nombre de publications contenant la phrase \"traitement du langage naturel\" dans PubMed au cours de la période 1978-2018. En 2018, PubMed comprenait plus de 29 millions de citations de la littérature biomédicale\n",
    "\n",
    "Des entreprises comme Winterlight Labs apportent d'énormes améliorations dans le traitement de la maladie d'Alzheimer en surveillant les troubles cognitifs par la parole et elles peuvent également soutenir des essais et des études cliniques pour un large éventail de troubles du système nerveux central. Suivant une approche similaire, l'université de Stanford a mis au point Woebot, un thérapeute de chatbot dans le but d'aider les personnes souffrant d'anxiété et d'autres troubles.\n",
    "\n",
    "Mais le sujet fait l'objet d'une sérieuse controverse. Il y a quelques années, Microsoft a démontré qu'en analysant de grands échantillons de requêtes sur les moteurs de recherche, elle pouvait identifier les internautes qui souffraient d'un cancer du pancréas avant même qu'ils n'aient reçu un diagnostic de la maladie. Comment les utilisateurs réagiraient-ils à un tel diagnostic ? Et que se passerait-il si vous étiez testé comme faux positif ? (ce qui signifie que vous pouvez être diagnostiqué avec la maladie même si vous ne l'avez pas). Cela rappelle le cas de Google Flu Trends qui, en 2009, a été annoncé comme étant capable de prédire la grippe, mais qui a ensuite disparu en raison de sa faible précision et de son incapacité à atteindre les taux prévus.\n",
    "\n",
    "La PNL peut être la clé d'un soutien clinique efficace à l'avenir, mais il reste de nombreux défis à relever à court terme.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "La PNL de base pour impressionner vos amis non PNL\n",
    "\n",
    "Les principaux inconvénients auxquels nous sommes confrontés ces jours-ci avec la PNL sont liés au fait que la langue est très délicate. Le processus de compréhension et de manipulation du langage est extrêmement complexe, et c'est pour cette raison qu'il est courant d'utiliser différentes techniques pour relever différents défis avant de tout relier. Les langages de programmation comme Python ou R sont très utilisés pour réaliser ces techniques, mais avant de plonger dans les lignes de code (ce sera le sujet d'un autre article), il est important de comprendre les concepts sous-jacents. Résumons et expliquons quelques-uns des algorithmes les plus fréquemment utilisés en PNL pour définir le vocabulaire des termes :\n",
    "\n",
    "\n",
    "\n",
    "Sac de mots\n",
    "\n",
    "C'est un modèle couramment utilisé qui vous permet de compter tous les mots d'un texte. Il crée essentiellement une matrice d'occurrences pour la phrase ou le document, sans tenir compte de la grammaire et de l'ordre des mots. Ces fréquences ou occurrences de mots sont ensuite utilisées comme caractéristiques pour former un classificateur.\n",
    "\n",
    "Pour donner un bref exemple, j'ai pris la première phrase de la chanson \"Across the Universe\" des Beatles :\n",
    "\n",
    "    Les mots s'écoulent comme une pluie sans fin dans un gobelet en papier,\n",
    "\n",
    "    Ils glissent en passant, ils s'échappent à travers l'univers\n",
    "\n",
    "Maintenant, comptons les mots :\n",
    "Image pour le courrier\n",
    "Image pour la poste\n",
    "\n",
    "Cette approche peut présenter plusieurs inconvénients, comme l'absence de sens sémantique et de contexte, et les faits qui font que les mots d'arrêt (comme \"le\" ou \"a\") ajoutent du bruit à l'analyse et que certains mots ne sont pas pondérés en conséquence (l'\"univers\" a un poids inférieur au mot \"ils\").\n",
    "\n",
    "Pour résoudre ce problème, une approche consiste à rééchelonner la fréquence des mots en fonction de la fréquence de leur apparition dans tous les textes (et pas seulement dans celui que nous analysons), de sorte que les scores des mots fréquents comme \"le\", qui sont également fréquents dans d'autres textes, soient pénalisés. Cette approche de la notation est appelée \"Fréquence des termes - Fréquence des documents inversés\" (TFIDF), et améliore le sac de mots par des pondérations. Grâce à la TFIDF, les termes fréquents dans le texte sont \"récompensés\" (comme le mot \"ils\" dans notre exemple), mais ils sont également \"punis\" si ces termes sont fréquents dans d'autres textes que nous incluons également dans l'algorithme. Au contraire, cette méthode met en évidence et \"récompense\" les termes uniques ou rares en considérant tous les textes. Néanmoins, cette approche n'a toujours pas de contexte ni de sémantique.\n",
    "\n",
    "Traduit avec www.DeepL.com/Translator (version gratuite)\n",
    "\n",
    "Tokenisation\n",
    "\n",
    "C'est le processus de segmentation du texte en phrases et en mots. Il s'agit essentiellement de découper un texte en morceaux appelés \"jetons\" et de jeter en même temps certains caractères, comme la ponctuation. Si l'on suit notre exemple, le résultat de la segmentation serait\n",
    "\n",
    "Plutôt simple, non ? Eh bien, bien que cela puisse sembler assez élémentaire dans ce cas et aussi dans des langues comme l'anglais qui séparent les mots par un espace vide (appelées langues segmentées), toutes les langues ne se comportent pas de la même manière, et si vous y réfléchissez, les espaces vides seuls ne sont pas suffisants, même pour l'anglais, pour effectuer des tokenisations correctes. Le fractionnement sur des espaces vides peut briser ce qui doit être considéré comme un seul jeton, comme dans le cas de certains noms (par exemple San Francisco ou New York) ou de phrases étrangères empruntées (par exemple laissez faire).\n",
    "\n",
    "Le jeton peut également supprimer la ponctuation, ce qui facilite le chemin vers une segmentation correcte des mots mais peut également entraîner des complications. Dans le cas des points qui suivent une abréviation (par exemple dr.), le point qui suit cette abréviation doit être considéré comme faisant partie du même jeton et ne doit pas être supprimé.\n",
    "\n",
    "Le processus de tokenisation peut être particulièrement problématique lorsqu'il s'agit de domaines de texte biomédical qui contiennent beaucoup de traits d'union, de parenthèses et d'autres signes de ponctuation.\n",
    "\n",
    "Pour plus de détails sur la tokenisation, vous trouverez une explication détaillée dans cet article.\n",
    "\n",
    "Suppression des mots d'arrêt\n",
    "\n",
    "Il s'agit notamment de se débarrasser des articles de langue courante, des pronoms et des prépositions tels que \"et\", \"le\" ou \"à\" en anglais. Dans ce processus, certains mots très courants qui semblent n'apporter que peu ou pas de valeur à l'objectif de la PNL sont filtrés et exclus du texte à traiter, ce qui permet de supprimer des termes répandus et fréquents qui ne sont pas informatifs sur le texte correspondant.\n",
    "\n",
    "Les mots d'arrêt peuvent être ignorés en toute sécurité en effectuant une recherche dans une liste prédéfinie de mots clés, ce qui libère de l'espace dans la base de données et améliore le temps de traitement.\n",
    "\n",
    "\n",
    "Il n'existe pas de liste universelle de mots vides. Ceux-ci peuvent être présélectionnés ou construits de toutes pièces. Une approche possible consiste à commencer par adopter des mots d'arrêt prédéfinis et à ajouter des mots à la liste par la suite. Néanmoins, il semble que la tendance générale au cours des dernières années soit de passer de l'utilisation de grandes listes standard de mots vides à l'utilisation de listes inexistantes.\n",
    "\n",
    "Le fait est que la suppression des mots d'arrêt peut effacer des informations pertinentes et modifier le contexte d'une phrase donnée. Par exemple, si nous effectuons une analyse des sentiments, nous risquons de faire dérailler notre algorithme si nous supprimons un mot d'arrêt comme \"non\". Dans ces conditions, vous pouvez sélectionner une liste minimale de mots vides et ajouter des termes supplémentaires en fonction de votre objectif spécifique.\n",
    "\n",
    "\n",
    "A la suite de\n",
    "\n",
    "Désigne le processus consistant à couper la fin ou le début des mots dans l'intention de supprimer les affixes (ajouts lexicaux à la racine du mot).\n",
    "\n",
    "    Les affixes qui sont attachés au début du mot sont appelés préfixes (par exemple \"astro\" dans le mot \"astrobiologie\") et ceux qui sont attachés à la fin du mot sont appelés suffixes (par exemple \"ful\" dans le mot \"utile\").\n",
    "\n",
    "Le problème est que les affixes peuvent créer ou étendre de nouvelles formes du même mot (appelés affixes inflexionnels), ou même créer de nouveaux mots eux-mêmes (appelés affixes dérivés). En anglais, les préfixes sont toujours dérivés (l'affixe crée un nouveau mot comme dans l'exemple du préfixe \"eco\" dans le mot \"ecosystem\"), mais les suffixes peuvent être dérivés (l'affixe crée un nouveau mot comme dans l'exemple du suffixe \"ist\" dans le mot \"guitarist\") ou flexionnels (l'affixe crée une nouvelle forme de mot comme dans l'exemple du suffixe \"er\" dans le mot \"faster\").\n",
    "\n",
    "\n",
    "Ok, alors comment pouvons-nous faire la différence et couper le bon morceau ?\n",
    ">>>>>> Image pour le poste\n",
    ">>>>>> Image pour la poste\n",
    "\n",
    "Une approche possible consiste à envisager une liste d'affixes et de règles communs (les langages Python et R ont des bibliothèques différentes contenant des affixes et des méthodes) et à effectuer des opérations de steming sur la base de ceux-ci, mais cette approche présente bien sûr des limites. Étant donné que les \"stemmers\" utilisent des approches algorithmiques, le résultat du processus de \"stemming\" peut ne pas être un mot réel ou même changer le sens du mot (et de la phrase). Pour compenser cet effet, vous pouvez modifier ces méthodes prédéfinies en ajoutant ou en supprimant des affixes et des règles, mais vous devez considérer que vous pourriez améliorer les performances dans un domaine tout en produisant une dégradation dans un autre. Regardez toujours l'ensemble du tableau et testez les performances de votre modèle.\n",
    "\n",
    "Ainsi, si l'éradication présente de sérieuses limites, pourquoi l'utiliser ? Tout d'abord, elle peut être utilisée pour corriger les erreurs d'orthographe des jetons. Les tiges sont simples à utiliser et fonctionnent très rapidement (elles effectuent des opérations simples sur une chaîne), et si la vitesse et les performances sont importantes dans le modèle de PNL, alors la tige est certainement la solution. N'oubliez pas que nous l'utilisons dans le but d'améliorer nos performances, et non comme un exercice de grammaire.\n",
    "\n",
    "\n",
    "\n",
    "Lemmatisation\n",
    "\n",
    "A pour objectif de réduire un mot à sa forme de base et de regrouper les différentes formes d'un même mot. Par exemple, les verbes au passé sont changés en présent (par exemple, \"allé\" est changé en \"go\") et les synonymes sont unifiés (par exemple, \"meilleur\" est changé en \"bon\"), ce qui permet de normaliser les mots dont le sens est similaire à celui de leur racine. Bien qu'elle semble étroitement liée au processus d'éradication, la lemmatisation utilise une approche différente pour atteindre les formes racines des mots.\n",
    "\n",
    "    La lemmatisation résout les mots à leur forme de dictionnaire (appelée lemme) pour laquelle elle nécessite des dictionnaires détaillés dans lesquels l'algorithme peut examiner et relier les mots à leurs lemmes correspondants.\n",
    "\n",
    "Par exemple, les mots \"running\", \"runs\" et \"ran\" sont tous des formes du mot \"run\", donc \"run\" est le lemme de tous les mots précédents.\n",
    ">>>>>>> Image pour l'article\n",
    ">>>>>>> Image pour la poste\n",
    "\n",
    "La lemmatisation prend également en considération le contexte du mot afin de résoudre d'autres problèmes comme la désambiguïsation, ce qui signifie qu'elle peut faire la distinction entre des mots identiques qui ont des significations différentes selon le contexte spécifique. Pensez à des mots comme \"batte\" (qui peut correspondre à l'animal ou au club de métal/bois utilisé au baseball) ou \"banque\" (qui correspond à l'institution financière ou à la terre le long d'un plan d'eau). En fournissant un paramètre de partie de discours à un mot ( que ce soit un nom, un verbe, etc.), il est possible de définir un rôle pour ce mot dans la phrase et de supprimer la désambiguïsation.\n",
    "\n",
    "Comme vous l'avez peut-être déjà imaginé, la lemmatisation est une tâche beaucoup plus exigeante en termes de ressources que l'exécution d'un processus d'endiguement. En même temps, comme elle exige plus de connaissances sur la structure de la langue qu'une approche de \"stemming\", elle demande plus de puissance de calcul que la mise en place ou l'adaptation d'un algorithme de \"stemming\".\n",
    "\n",
    "Modélisation des sujets\n",
    "\n",
    "C'est une méthode pour découvrir des structures cachées dans des ensembles de textes ou de documents. Il s'agit essentiellement de regrouper des textes pour découvrir des sujets latents en fonction de leur contenu, en traitant des mots individuels et en leur attribuant des valeurs en fonction de leur distribution. Cette technique est basée sur l'hypothèse que chaque document est constitué d'un mélange de sujets et que chaque sujet est constitué d'un ensemble de mots, ce qui signifie que si nous pouvons repérer ces sujets cachés, nous pouvons débloquer le sens de nos textes.\n",
    "\n",
    "Dans l'univers des techniques de modélisation des sujets, l'allocation de Dirichlet latent (ADL) est probablement la plus utilisée. Cet algorithme relativement nouveau (inventé il y a moins de 20 ans) fonctionne comme une méthode d'apprentissage non supervisée qui permet de découvrir différents sujets sous-jacents à une collection de documents. Dans les méthodes d'apprentissage non supervisées comme celle-ci, il n'y a pas de variable de sortie pour guider le processus d'apprentissage et les données sont explorées par des algorithmes pour trouver des modèles. Pour être plus précis, LDA trouve des groupes de mots apparentés par :\n",
    "\n",
    "    En assignant chaque mot à un sujet aléatoire, où l'utilisateur définit le nombre de sujets qu'il souhaite découvrir. Vous ne définissez pas les sujets eux-mêmes (vous définissez seulement le nombre de sujets) et l'algorithme mettra en correspondance tous les documents avec les sujets de manière à ce que les mots de chaque document soient principalement capturés par ces sujets imaginaires.\n",
    "    L'algorithme passe chaque mot en revue de manière itérative et réassigne le mot à un sujet en tenant compte de la probabilité que le mot appartienne à un sujet et de la probabilité que le document soit généré par un sujet. Ces probabilités sont calculées plusieurs fois, jusqu'à la convergence de l'algorithme.\n",
    "\n",
    "Contrairement à d'autres algorithmes de regroupement comme K-means qui effectuent un regroupement dur (où les sujets sont disjoints), LDA assigne chaque document à un mélange de sujets, ce qui signifie que chaque document peut être décrit par un ou plusieurs sujets (par exemple, le document 1 est décrit par 70% du sujet A, 20% du sujet B et 10% du sujet C) et reflète des résultats plus réalistes.\n",
    ">>>>>>>> Image pour le poste\n",
    ">>>>>>>> Image pour la poste\n",
    "\n",
    "La modélisation thématique est extrêmement utile pour classer les textes, établir des systèmes de recommandation (par exemple pour vous recommander des livres en fonction de vos lectures antérieures) ou même détecter des tendances dans les publications en ligne.\n",
    "\n",
    "\n",
    "\n",
    "À quoi ressemble l'avenir ?\n",
    "\n",
    "En ce moment, la PNL se bat pour détecter les nuances dans la signification des langues, qu'elles soient dues à un manque de contexte, à des erreurs d'orthographe ou à des différences dialectales.\n",
    "\n",
    "En mars 2016, Microsoft a lancé Tay, un chatbot d'intelligence artificielle (IA) publié sur Twitter comme expérience de PNL. L'idée était que plus les utilisateurs parleraient avec Tay, plus il serait intelligent. Le résultat a été qu'après 16 heures, Tay a dû être supprimé en raison de ses commentaires racistes et abusifs :\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***************\n",
    "LIEN 3\n",
    "En francais, ok\n",
    "\n",
    "https://code.tutsplus.com/fr/tutorials/introducing-the-natural-language-toolkit-nltk--cms-28620\n",
    "\n",
    "*****************\n",
    "LIEN 4\n",
    "https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
